{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94664a6a-7b98-472d-9e4e-922dd9acc2a4",
   "metadata": {},
   "source": [
    "<h2>Exercise 1 - A data scientist is running an AdaBoost classifier on a dataset with 100 observations. Answer the\n",
    "following:</h2>\n",
    "\n",
    "1a) Initial weight of observation 72 is 1/100 since there are 100 observations and they are all weighted equally to begin with.\n",
    "\n",
    "1b) The 72nd observation being misclassified means that the new weight assigned to it will be *larger* than the initial weight. This is because we want it to get more attention since it was wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10a140-838e-4b5d-8288-f02ce29b485c",
   "metadata": {},
   "source": [
    "<h2>Exercise 2 - Explain why AbaBoost is an ensemble learning algorithm? Be specific.</h2>\n",
    "\n",
    "**Answer:** It takes a bunch of weak learners to make a strong learner. The data points with the most errors get larger weights. Each model learns from the previous one and they form a much better predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78250668-a8a6-40d1-855d-b375b4e71ae6",
   "metadata": {},
   "source": [
    "<h2>Exercise 3 - refer to picture taken of handwritten work</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18ca73-0425-4b98-9481-7b7b402213c5",
   "metadata": {},
   "source": [
    "<h2>Exercise 4 - If your AdaBoost ensemble under-fits the training dataset, what would you do to fix\n",
    "that? That is, which hyper-parameters should you tweak?</h2>\n",
    "\n",
    "**Answer:** Increase the number of estimators to learn from more weak learners and the learning rate since those two go together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8a65f-8510-4724-a3e2-f169a3146290",
   "metadata": {},
   "source": [
    "<h2>Exercise 5 - For binary classification, which of the following statements are TRUE of AdaBoost with decision trees as learners?</h2>\n",
    "\n",
    "**Answer:** A, B, & C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fd61b-a283-432e-9e0d-4b0665668d66",
   "metadata": {},
   "source": [
    "<h2>Exercise 6 - Which of the following is/are TRUE about gradient boosting trees?</h2>\n",
    "\n",
    "**Answer:** F (so both b and c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ee02a-f94c-4ae7-b5b0-4747a76fe0e0",
   "metadata": {},
   "source": [
    "<h2>Exercise 7 - In this course have covered two boosting frameworks. What is the main difference\n",
    "between AdaBoost and Gradient Boosting? Be specific.</h2>\n",
    "\n",
    "**Answer:** AdaBoost weighs previous misclassified observations by weighting them larger. Gradient Boosting fits the weak learners to the residuals/errors of the previous learners. Gradient boosting trains on minimizing the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f86e0-c509-4ee0-91e8-2f4c080efd39",
   "metadata": {},
   "source": [
    "<h2>Exercise 8 - Use framingham datafile to answer questions below</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258584cd-06a5-4771-974d-8205cec36dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8a - read the csv data file and create a data-frame called heart. Remove the observations with missing values.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "heart = pd.read_csv('framingham(4).csv')\n",
    "heart = heart.dropna()\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4114e85f-856c-4595-84f3-be4ca69918bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8b ###\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Predictor variables = age, totChol, sysBP, BMI, heartRate, and glucose\n",
    "#Target variables = TenYearCHD\n",
    "\n",
    "X = heart[['age', 'totChol' , 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "#We will store our recall and accuracy scores here\n",
    "RF_recall = list()\n",
    "ET_recall = list()\n",
    "Ada_recall = list()\n",
    "GB_recall = list()\n",
    "RF_accuracy = list()\n",
    "ET_accuracy = list()\n",
    "Ada_accuracy = list()\n",
    "GB_accuracy = list()\n",
    "\n",
    "#Repeat 100 times\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    #Split data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "\n",
    "    ### Random Forest Classifier ###\n",
    "    RF_md = RandomForestClassifier(n_estimators = 500, max_depth = 5).fit(X_train, Y_train)\n",
    "    \n",
    "    #Predict\n",
    "    RF_pred = RF_md.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #Labels with 10% cutoff\n",
    "    RF_labels = np.where(RF_pred < 0.1, 0, 1)\n",
    "    RF_recall.append(recall_score(Y_test, RF_labels))\n",
    "    RF_accuracy.append(accuracy_score(Y_test, RF_labels))\n",
    "\n",
    "\n",
    "    ### Extra Trees Classifier ###\n",
    "    ET_md = ExtraTreesClassifier(n_estimators = 500, max_depth = 5).fit(X_train, Y_train)\n",
    "    \n",
    "    #Predict\n",
    "    ET_pred = ET_md.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #Labels with 10% cutoff\n",
    "    ET_labels = np.where(ET_pred < 0.1, 0, 1)\n",
    "    ET_recall.append(recall_score(Y_test, ET_labels))\n",
    "    ET_accuracy.append(accuracy_score(Y_test, ET_labels))\n",
    "\n",
    "    \n",
    "    ### AdaBoost ###\n",
    "    Ada_md = AdaBoostClassifier(estimator = DecisionTreeClassifier(max_depth = 3), \n",
    "                                n_estimators = 500,\n",
    "                                learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    #Predict\n",
    "    Ada_pred = Ada_md.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #Labels with 10% cutoff\n",
    "    Ada_labels = np.where(Ada_pred < 0.1, 0, 1)\n",
    "    Ada_recall.append(recall_score(Y_test, Ada_labels))\n",
    "    Ada_accuracy.append(accuracy_score(Y_test, Ada_labels))\n",
    "\n",
    "    \n",
    "    ### Gradient Boosting ###\n",
    "    GB_md = GradientBoostingClassifier(max_depth = 3,\n",
    "                                       n_estimators = 500, \n",
    "                                       learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    #Predict\n",
    "    GB_pred = GB_md.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #Labels with 10% cutoff\n",
    "    GB_labels = np.where(GB_pred < 0.1, 0, 1)\n",
    "    GB_recall.append(recall_score(Y_test, GB_labels))\n",
    "    GB_accuracy.append(accuracy_score(Y_test, GB_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81bf1a2-b120-44a5-b1e6-b862bfcf9cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF recall:  0.8361607142857141\n",
      "RF accuracy:  0.48892076502732246\n",
      "ET recall:  0.9362500000000001\n",
      "ET accuracy:  0.33814207650273226\n",
      "Ada recall:  0.9914285714285715\n",
      "Ada accuracy:  0.15834699453551915\n",
      "GB recall:  0.8115178571428572\n",
      "GB accuracy:  0.5068169398907104\n"
     ]
    }
   ],
   "source": [
    "#Average accuracy and recall of each model above\n",
    "print('RF recall: ', np.mean(RF_recall))\n",
    "print('RF accuracy: ', np.mean(RF_accuracy))\n",
    "\n",
    "print('ET recall: ', np.mean(ET_recall))\n",
    "print('ET accuracy: ', np.mean(ET_accuracy))\n",
    "\n",
    "print('Ada recall: ', np.mean(Ada_recall))\n",
    "print('Ada accuracy: ', np.mean(Ada_accuracy))\n",
    "\n",
    "print('GB recall: ', np.mean(GB_recall))\n",
    "print('GB accuracy: ', np.mean(GB_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5854d4b-5725-42ef-8555-776fbe8d136a",
   "metadata": {},
   "source": [
    "From the above, I would use RF or GB since the recall is fairly high without having a very low accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6aa731-60ce-4b76-95a7-af02bbafc11e",
   "metadata": {},
   "source": [
    "<h4>### 8c ###</h4>\n",
    "\n",
    "All of the models have a recall over 80% but none of them have an accuracy over 80%. We could play around with the max_depth, n_estimators, and learning_rate to try and reach 80%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
