{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "745e2582-2dd3-43f1-8a42-b09d591862ef",
   "metadata": {},
   "source": [
    "### Exercise 1 - Given 1000 records in a dataset, 1000 models are trained with 999 records as part of the training sample and the remaining 1 sample for testing, and the error rate is averaged out, this validation technique is called what?\n",
    "\n",
    "Answer: LOOCV (leave-one-out cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7891dee-64fb-4840-b73a-e6ca1836a1a1",
   "metadata": {},
   "source": [
    "### Exercise 2 - In k-fold cross validation technique, the value of k being small could lead to which of the following in relation to the error rate?\n",
    "\n",
    "Answer: High bias and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50e4c7-efa1-4751-9e81-af6886a7adc7",
   "metadata": {},
   "source": [
    "### Exercise 3 - In k-fold cross validation technique, the value of k being large could lead to which of the following in relation to the error rate?\n",
    "\n",
    "Answer: Low bias and high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ccc75-af85-411a-b1c8-b3cfd0d83941",
   "metadata": {},
   "source": [
    "### Exercise 4 - Explain what regularization is and why it is useful.\n",
    "\n",
    "Answer: Fitting a model with all the input variables. It shrinks the variables towards zero relative to the least squares estimates. This helps with reducing variance. The two best techiqnues for shrinking the regression coefficients towards zero are *ridge regression* and the *LASSO*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ffe84d-f74a-47f5-92be-46ba2e5828ea",
   "metadata": {},
   "source": [
    "### Exercise 5 - Use framingham.csv data file. It is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD). The dataset provides the patients' information. It includes over 4,000 records and 15 attributes. Each attribute is a potential risk factor. There are both demographic, behavioral and medical risk factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1785dff5-98ca-4c8c-b863-0fe2af1fb956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 5a - Using the pandas library, read the csv data file and create a data-frame called heart. ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "heart = pd.read_csv('framingham.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca895a3-5315-4fa4-b0a0-a7de1b5b05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5b - Remove observations with missing values ###\n",
    "\n",
    "heart = heart.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdab2ecc-53dc-476e-b994-01ace29eb576",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:  [0.3448275862068966, 0.38267148014440433, 0.3679525222551929, 0.2857142857142857, 0.3951367781155015] \n",
      "\n",
      "Model 2:  [0.36090225563909767, 0.3206751054852321, 0.34532374100719426, 0.32131147540983607, 0.35179153094462545]\n"
     ]
    }
   ],
   "source": [
    "### 5c - Perform a 5-folds cross validation with the goal of measuring the performance\n",
    "### in terms of F1-score, of two competing models:\n",
    "\n",
    "#TenYearCHD is target variable\n",
    "X = heart.drop(columns = ['TenYearCHD'], axis=1)\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "#5 KFolds cross validation\n",
    "k_fold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "#Empty lists to store f1 score results\n",
    "score_1 = list()\n",
    "score_2 = list()\n",
    "\n",
    "for train_idx, val_idx in k_fold.split(X):\n",
    "    #Split data\n",
    "    X_train, X_val = X.iloc[train_idx],X.iloc[val_idx]\n",
    "    Y_train, Y_val = Y.iloc[train_idx],Y.iloc[val_idx]\n",
    "    \n",
    "    ### Model 1 ###\n",
    "    X_1 = X_train[['age', 'currentSmoker', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\n",
    "    X_val_1 = X_val[['age', 'currentSmoker', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\n",
    "    \n",
    "    #Scaling input variables\n",
    "    scaler = MinMaxScaler()\n",
    "    X_1 = scaler.fit_transform(X_1)\n",
    "    X_val_1 = scaler.fit_transform(X_val_1)\n",
    "    \n",
    "    md_1 = LogisticRegression().fit(X_1, Y_train)\n",
    "    \n",
    "    #Predicting\n",
    "    pred_1 = md_1.predict_proba(X_val_1)[:,1]\n",
    "    \n",
    "    #25% threshold, change likelihood to labels\n",
    "    pred_1_label = np.where(pred_1 < 0.25, 0, 1)\n",
    "    \n",
    "    #f1 score model 1\n",
    "    score_1.append(f1_score(Y_val, pred_1_label))\n",
    "    \n",
    "    ### Model 2 - Got rid of sysBP and diaBP from input variables ###\n",
    "    X_2 = X_train[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate', 'glucose']]\n",
    "    X_val_2 = X_val[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate', 'glucose']]\n",
    "    \n",
    "    #Scaling input variables\n",
    "    X_2 = scaler.fit_transform(X_2)\n",
    "    X_val_2 = scaler.fit_transform(X_val_2)    \n",
    "    \n",
    "    md_2 = LogisticRegression().fit(X_2, Y_train)\n",
    "    \n",
    "    #Predicting\n",
    "    pred_2 = md_2.predict_proba(X_val_2)[:,1]\n",
    "    \n",
    "    #25% threshold, change likelihood to labels\n",
    "    pred_2_label = np.where(pred_2 < 0.25, 0, 1)\n",
    "    \n",
    "    #f1 score model 2\n",
    "    score_2.append(f1_score(Y_val, pred_2_label))\n",
    "    \n",
    "print('Model 1: ', score_1, '\\n')\n",
    "print('Model 2: ', score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcf352d0-9b3b-4724-b5a6-f0742b72fc54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f1 score of model 1:  0.3552605304872562\n",
      "Average f1 score of model 2:  0.3400008216971971\n"
     ]
    }
   ],
   "source": [
    "### 5d - Report the average F1-score of each of the models. \n",
    "### What model would you use to predict TenYearCHD? Explain\n",
    "\n",
    "print('Average f1 score of model 1: ', np.mean(score_1))\n",
    "print('Average f1 score of model 2: ', np.mean(score_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3f632-c9db-4188-808b-b24a19ec9a9f",
   "metadata": {},
   "source": [
    "From the above, I would use model 1 to predict TenYearCHD because the f1 score of model 1 is higher.\n",
    "f1 scales from 0 to 1, a higher f1 score means that the model better represents each observation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
